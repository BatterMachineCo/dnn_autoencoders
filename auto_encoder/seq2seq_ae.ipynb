{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TocO_lcqXD0d",
   "metadata": {
    "id": "TocO_lcqXD0d"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "File Name: seq2seq_ae.ipynb\n",
    "\n",
    "Description: seq2seq auto encoder\n",
    "\n",
    "Author: junghwan lee\n",
    "Email: jhrrlee@gmail.com\n",
    "Date Created: 2023.09.12\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c3b5889-7b4c-45b8-85f7-fe12d18c5ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, Dense, AdditiveAttention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "\n",
    "def create_seq2seq_ae_v1(no_of_timeseries, no_of_features):\n",
    "    input_shape = (no_of_timeseries, no_of_features)\n",
    "    initializer = HeNormal(42)\n",
    "\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=input_shape)\n",
    "    print(encoder_inputs.shape)\n",
    "    encoded = LSTM(no_of_features, return_sequences=False, kernel_initializer=initializer)(encoder_inputs)\n",
    "\n",
    "    # Decoder\n",
    "    decoder_inputs = RepeatVector(no_of_timeseries)(encoded)\n",
    "    print(decoder_inputs.shape)\n",
    "    decoded = LSTM(no_of_features, return_sequences=True, kernel_initializer=initializer)(decoder_inputs)\n",
    "\n",
    "    # Autoencoder\n",
    "    autoencoder = Model(encoder_inputs, decoded)\n",
    "    encoder = Model(encoder_inputs, encoded)\n",
    "\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e7ae662-cb1d-49a2-b9df-4f3ca048ff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed, Reshape\n",
    "\n",
    "def create_seq2seq_ae_v2(no_of_timeseries, no_of_features):\n",
    "    input_shape = (no_of_timeseries, no_of_features)\n",
    "    initializer = HeNormal(42)\n",
    "\n",
    "    # Determine the chunk size and number of chunks\n",
    "    num_chunks = 10\n",
    "    chunk_size = no_of_timeseries // num_chunks\n",
    "\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=input_shape)\n",
    "    x = Reshape((num_chunks, chunk_size, no_of_features))(encoder_inputs)\n",
    "    encoded_chunks = TimeDistributed(LSTM(no_of_features, return_sequences=False, kernel_initializer=initializer))(x)\n",
    "    # expected dimension of encoded_chunks (num_chunks, no_of_features)\n",
    "\n",
    "    # Decoder\n",
    "    x = TimeDistributed(RepeatVector(chunk_size))(encoded_chunks)\n",
    "    x = Reshape((num_chunks, chunk_size, no_of_features))(x)\n",
    "\n",
    "    decoded_chunks = TimeDistributed(LSTM(no_of_features, return_sequences=True, kernel_initializer=initializer))(x)\n",
    "\n",
    "    # Reshape the decoded chunks back to the original input shape\n",
    "    decoded = Reshape((no_of_timeseries, no_of_features))(decoded_chunks)\n",
    "\n",
    "    # Autoencoder\n",
    "    autoencoder = Model(encoder_inputs, decoded)\n",
    "\n",
    "    # Encoder Model (Optional, in case you need it later)\n",
    "    encoder = Model(encoder_inputs, encoded_chunks)\n",
    "\n",
    "    return autoencoder, encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "555fdfaa-1de6-4d70-80ae-f6ad02f9621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq2seq_ae_v3(no_of_timeseries, no_of_features):\n",
    "    input_shape = (no_of_timeseries, no_of_features)\n",
    "    initializer = HeNormal(42)\n",
    "\n",
    "    # Determine the chunk size and number of chunks\n",
    "    num_chunks = 10\n",
    "    chunk_size = no_of_timeseries // num_chunks\n",
    "\n",
    "    # Encoder\n",
    "    encoder_inputs = Input(shape=input_shape)\n",
    "    x = Reshape((num_chunks, chunk_size, no_of_features))(encoder_inputs)\n",
    "    x = TimeDistributed(LSTM(no_of_features, return_sequences=False, kernel_initializer=initializer))(x) # (10, 8)\n",
    "    encoded = LSTM(no_of_features, return_sequences=False, kernel_initializer=initializer)(x) # (1, 8)\n",
    "    # expected dimension of encoded_chunks (num_chunks, no_of_features)\n",
    "\n",
    "    # Decoder\n",
    "    x = RepeatVector(num_chunks)(encoded) # (10, 8)\n",
    "    x = LSTM(no_of_features, return_sequences=True, kernel_initializer=initializer)(x) # (10, 8)\n",
    "    x = TimeDistributed(RepeatVector(chunk_size))(x) # (1000, 8)\n",
    "    x = Reshape((num_chunks, chunk_size, no_of_features))(x) # (10, 100, 8)\n",
    "    decoded_chunks = TimeDistributed(LSTM(no_of_features, return_sequences=True, kernel_initializer=initializer))(x)\n",
    "\n",
    "    # Reshape the decoded chunks back to the original input shape\n",
    "    decoded = Reshape((no_of_timeseries, no_of_features))(decoded_chunks)\n",
    "\n",
    "    # Autoencoder\n",
    "    autoencoder = Model(encoder_inputs, decoded)\n",
    "\n",
    "    # Encoder Model (Optional, in case you need it later)\n",
    "    encoder = Model(encoder_inputs, encoded)\n",
    "\n",
    "    return autoencoder, encoder\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
